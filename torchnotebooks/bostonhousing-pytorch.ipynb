{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.264358Z",
     "start_time": "2024-12-05T11:51:56.243699Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from thinc.layers.padded2list import forward"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.324309Z",
     "start_time": "2024-12-05T11:51:56.288291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "df.head()"
   ],
   "id": "ca6b67bf832dce6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      RM  LSTAT  PTRATIO      MEDV\n",
       "0  6.575   4.98     15.3  504000.0\n",
       "1  6.421   9.14     17.8  453600.0\n",
       "2  7.185   4.03     17.8  728700.0\n",
       "3  6.998   2.94     18.7  701400.0\n",
       "4  7.147   5.33     18.7  760200.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "      <td>504000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "      <td>453600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "      <td>728700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "      <td>701400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "      <td>760200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.413602Z",
     "start_time": "2024-12-05T11:51:56.409372Z"
    }
   },
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "53391cf8a224cda3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RM         0\n",
       "LSTAT      0\n",
       "PTRATIO    0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.472248Z",
     "start_time": "2024-12-05T11:51:56.467371Z"
    }
   },
   "cell_type": "code",
   "source": "sum(df.duplicated())",
   "id": "7900f0b05f3691c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.508601Z",
     "start_time": "2024-12-05T11:51:56.505735Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns = df.columns.str.lower()",
   "id": "93cbaf33781acab4",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.535576Z",
     "start_time": "2024-12-05T11:51:56.532300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ],
   "id": "ea58e48814b76c52",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.574393Z",
     "start_time": "2024-12-05T11:51:56.567914Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)",
   "id": "fc3c262101409cf1",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.600901Z",
     "start_time": "2024-12-05T11:51:56.598297Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_test.shape, y_train.shape, y_test.shape",
   "id": "a4667eca0db08299",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((391, 3), (98, 3), (391,), (98,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.622144Z",
     "start_time": "2024-12-05T11:51:56.619177Z"
    }
   },
   "cell_type": "code",
   "source": "type(X_train)",
   "id": "83baa285253d144",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.645140Z",
     "start_time": "2024-12-05T11:51:56.642431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "9a53685ad3ba7d2f",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.664148Z",
     "start_time": "2024-12-05T11:51:56.662714Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "8a67457bf9f2c19d",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.684433Z",
     "start_time": "2024-12-05T11:51:56.681314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ],
   "id": "f85d93e75ed45f6d",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.709717Z",
     "start_time": "2024-12-05T11:51:56.707177Z"
    }
   },
   "cell_type": "code",
   "source": "type(X_train_tensor)",
   "id": "c01bfba616d76ba8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.778190Z",
     "start_time": "2024-12-05T11:51:56.775153Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_test.shape, y_train.shape, y_test.shape",
   "id": "d9a9753a06db5894",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((391, 3), (98, 3), torch.Size([391]), torch.Size([98]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.954192Z",
     "start_time": "2024-12-05T11:51:56.869414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.network(features)\n",
    "\n",
    "# Define the model\n",
    "num_features = X_train_tensor.shape[1]\n",
    "model = Model(num_features)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)  # Use Adam for better optimization\n",
    "loss_function = nn.MSELoss()  # For binary classification\n",
    "\n",
    "# Training Loop\n",
    "epochs = 250\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = loss_function(y_pred.squeeze(), y_train)  # Squeeze for shape matching\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ],
   "id": "638434e33d1562df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 231878197248.0000\n",
      "Epoch [2/250], Loss: 231878066176.0000\n",
      "Epoch [3/250], Loss: 231877918720.0000\n",
      "Epoch [4/250], Loss: 231877738496.0000\n",
      "Epoch [5/250], Loss: 231877607424.0000\n",
      "Epoch [6/250], Loss: 231877459968.0000\n",
      "Epoch [7/250], Loss: 231877279744.0000\n",
      "Epoch [8/250], Loss: 231877132288.0000\n",
      "Epoch [9/250], Loss: 231876952064.0000\n",
      "Epoch [10/250], Loss: 231876804608.0000\n",
      "Epoch [11/250], Loss: 231876657152.0000\n",
      "Epoch [12/250], Loss: 231876509696.0000\n",
      "Epoch [13/250], Loss: 231876329472.0000\n",
      "Epoch [14/250], Loss: 231876214784.0000\n",
      "Epoch [15/250], Loss: 231876034560.0000\n",
      "Epoch [16/250], Loss: 231875887104.0000\n",
      "Epoch [17/250], Loss: 231875739648.0000\n",
      "Epoch [18/250], Loss: 231875559424.0000\n",
      "Epoch [19/250], Loss: 231875395584.0000\n",
      "Epoch [20/250], Loss: 231875280896.0000\n",
      "Epoch [21/250], Loss: 231875084288.0000\n",
      "Epoch [22/250], Loss: 231874936832.0000\n",
      "Epoch [23/250], Loss: 231874805760.0000\n",
      "Epoch [24/250], Loss: 231874641920.0000\n",
      "Epoch [25/250], Loss: 231874461696.0000\n",
      "Epoch [26/250], Loss: 231874297856.0000\n",
      "Epoch [27/250], Loss: 231874166784.0000\n",
      "Epoch [28/250], Loss: 231874002944.0000\n",
      "Epoch [29/250], Loss: 231873871872.0000\n",
      "Epoch [30/250], Loss: 231873691648.0000\n",
      "Epoch [31/250], Loss: 231873527808.0000\n",
      "Epoch [32/250], Loss: 231873396736.0000\n",
      "Epoch [33/250], Loss: 231873249280.0000\n",
      "Epoch [34/250], Loss: 231873069056.0000\n",
      "Epoch [35/250], Loss: 231872905216.0000\n",
      "Epoch [36/250], Loss: 231872757760.0000\n",
      "Epoch [37/250], Loss: 231872610304.0000\n",
      "Epoch [38/250], Loss: 231872430080.0000\n",
      "Epoch [39/250], Loss: 231872299008.0000\n",
      "Epoch [40/250], Loss: 231872151552.0000\n",
      "Epoch [41/250], Loss: 231871954944.0000\n",
      "Epoch [42/250], Loss: 231871823872.0000\n",
      "Epoch [43/250], Loss: 231871660032.0000\n",
      "Epoch [44/250], Loss: 231871512576.0000\n",
      "Epoch [45/250], Loss: 231871381504.0000\n",
      "Epoch [46/250], Loss: 231871201280.0000\n",
      "Epoch [47/250], Loss: 231871037440.0000\n",
      "Epoch [48/250], Loss: 231870889984.0000\n",
      "Epoch [49/250], Loss: 231870742528.0000\n",
      "Epoch [50/250], Loss: 231870562304.0000\n",
      "Epoch [51/250], Loss: 231870398464.0000\n",
      "Epoch [52/250], Loss: 231870267392.0000\n",
      "Epoch [53/250], Loss: 231870119936.0000\n",
      "Epoch [54/250], Loss: 231869956096.0000\n",
      "Epoch [55/250], Loss: 231869808640.0000\n",
      "Epoch [56/250], Loss: 231869644800.0000\n",
      "Epoch [57/250], Loss: 231869497344.0000\n",
      "Epoch [58/250], Loss: 231869349888.0000\n",
      "Epoch [59/250], Loss: 231869169664.0000\n",
      "Epoch [60/250], Loss: 231869022208.0000\n",
      "Epoch [61/250], Loss: 231868874752.0000\n",
      "Epoch [62/250], Loss: 231868694528.0000\n",
      "Epoch [63/250], Loss: 231868547072.0000\n",
      "Epoch [64/250], Loss: 231868383232.0000\n",
      "Epoch [65/250], Loss: 231868219392.0000\n",
      "Epoch [66/250], Loss: 231868071936.0000\n",
      "Epoch [67/250], Loss: 231867924480.0000\n",
      "Epoch [68/250], Loss: 231867777024.0000\n",
      "Epoch [69/250], Loss: 231867629568.0000\n",
      "Epoch [70/250], Loss: 231867449344.0000\n",
      "Epoch [71/250], Loss: 231867301888.0000\n",
      "Epoch [72/250], Loss: 231867138048.0000\n",
      "Epoch [73/250], Loss: 231867006976.0000\n",
      "Epoch [74/250], Loss: 231866826752.0000\n",
      "Epoch [75/250], Loss: 231866662912.0000\n",
      "Epoch [76/250], Loss: 231866531840.0000\n",
      "Epoch [77/250], Loss: 231866368000.0000\n",
      "Epoch [78/250], Loss: 231866204160.0000\n",
      "Epoch [79/250], Loss: 231866056704.0000\n",
      "Epoch [80/250], Loss: 231865909248.0000\n",
      "Epoch [81/250], Loss: 231865712640.0000\n",
      "Epoch [82/250], Loss: 231865581568.0000\n",
      "Epoch [83/250], Loss: 231865434112.0000\n",
      "Epoch [84/250], Loss: 231865270272.0000\n",
      "Epoch [85/250], Loss: 231865122816.0000\n",
      "Epoch [86/250], Loss: 231864958976.0000\n",
      "Epoch [87/250], Loss: 231864811520.0000\n",
      "Epoch [88/250], Loss: 231864647680.0000\n",
      "Epoch [89/250], Loss: 231864500224.0000\n",
      "Epoch [90/250], Loss: 231864336384.0000\n",
      "Epoch [91/250], Loss: 231864172544.0000\n",
      "Epoch [92/250], Loss: 231864025088.0000\n",
      "Epoch [93/250], Loss: 231863877632.0000\n",
      "Epoch [94/250], Loss: 231863697408.0000\n",
      "Epoch [95/250], Loss: 231863566336.0000\n",
      "Epoch [96/250], Loss: 231863402496.0000\n",
      "Epoch [97/250], Loss: 231863255040.0000\n",
      "Epoch [98/250], Loss: 231863091200.0000\n",
      "Epoch [99/250], Loss: 231862927360.0000\n",
      "Epoch [100/250], Loss: 231862763520.0000\n",
      "Epoch [101/250], Loss: 231862632448.0000\n",
      "Epoch [102/250], Loss: 231862452224.0000\n",
      "Epoch [103/250], Loss: 231862321152.0000\n",
      "Epoch [104/250], Loss: 231862157312.0000\n",
      "Epoch [105/250], Loss: 231861977088.0000\n",
      "Epoch [106/250], Loss: 231861829632.0000\n",
      "Epoch [107/250], Loss: 231861682176.0000\n",
      "Epoch [108/250], Loss: 231861534720.0000\n",
      "Epoch [109/250], Loss: 231861354496.0000\n",
      "Epoch [110/250], Loss: 231861239808.0000\n",
      "Epoch [111/250], Loss: 231861075968.0000\n",
      "Epoch [112/250], Loss: 231860895744.0000\n",
      "Epoch [113/250], Loss: 231860764672.0000\n",
      "Epoch [114/250], Loss: 231860617216.0000\n",
      "Epoch [115/250], Loss: 231860436992.0000\n",
      "Epoch [116/250], Loss: 231860273152.0000\n",
      "Epoch [117/250], Loss: 231860142080.0000\n",
      "Epoch [118/250], Loss: 231859961856.0000\n",
      "Epoch [119/250], Loss: 231859830784.0000\n",
      "Epoch [120/250], Loss: 231859666944.0000\n",
      "Epoch [121/250], Loss: 231859519488.0000\n",
      "Epoch [122/250], Loss: 231859372032.0000\n",
      "Epoch [123/250], Loss: 231859191808.0000\n",
      "Epoch [124/250], Loss: 231859027968.0000\n",
      "Epoch [125/250], Loss: 231858896896.0000\n",
      "Epoch [126/250], Loss: 231858716672.0000\n",
      "Epoch [127/250], Loss: 231858569216.0000\n",
      "Epoch [128/250], Loss: 231858405376.0000\n",
      "Epoch [129/250], Loss: 231858274304.0000\n",
      "Epoch [130/250], Loss: 231858094080.0000\n",
      "Epoch [131/250], Loss: 231857946624.0000\n",
      "Epoch [132/250], Loss: 231857815552.0000\n",
      "Epoch [133/250], Loss: 231857635328.0000\n",
      "Epoch [134/250], Loss: 231857471488.0000\n",
      "Epoch [135/250], Loss: 231857324032.0000\n",
      "Epoch [136/250], Loss: 231857160192.0000\n",
      "Epoch [137/250], Loss: 231857012736.0000\n",
      "Epoch [138/250], Loss: 231856881664.0000\n",
      "Epoch [139/250], Loss: 231856701440.0000\n",
      "Epoch [140/250], Loss: 231856537600.0000\n",
      "Epoch [141/250], Loss: 231856390144.0000\n",
      "Epoch [142/250], Loss: 231856226304.0000\n",
      "Epoch [143/250], Loss: 231856078848.0000\n",
      "Epoch [144/250], Loss: 231855931392.0000\n",
      "Epoch [145/250], Loss: 231855783936.0000\n",
      "Epoch [146/250], Loss: 231855587328.0000\n",
      "Epoch [147/250], Loss: 231855456256.0000\n",
      "Epoch [148/250], Loss: 231855308800.0000\n",
      "Epoch [149/250], Loss: 231855144960.0000\n",
      "Epoch [150/250], Loss: 231854981120.0000\n",
      "Epoch [151/250], Loss: 231854833664.0000\n",
      "Epoch [152/250], Loss: 231854669824.0000\n",
      "Epoch [153/250], Loss: 231854522368.0000\n",
      "Epoch [154/250], Loss: 231854391296.0000\n",
      "Epoch [155/250], Loss: 231854194688.0000\n",
      "Epoch [156/250], Loss: 231854030848.0000\n",
      "Epoch [157/250], Loss: 231853899776.0000\n",
      "Epoch [158/250], Loss: 231853752320.0000\n",
      "Epoch [159/250], Loss: 231853555712.0000\n",
      "Epoch [160/250], Loss: 231853424640.0000\n",
      "Epoch [161/250], Loss: 231853277184.0000\n",
      "Epoch [162/250], Loss: 231853096960.0000\n",
      "Epoch [163/250], Loss: 231852965888.0000\n",
      "Epoch [164/250], Loss: 231852802048.0000\n",
      "Epoch [165/250], Loss: 231852654592.0000\n",
      "Epoch [166/250], Loss: 231852507136.0000\n",
      "Epoch [167/250], Loss: 231852343296.0000\n",
      "Epoch [168/250], Loss: 231852179456.0000\n",
      "Epoch [169/250], Loss: 231852048384.0000\n",
      "Epoch [170/250], Loss: 231851851776.0000\n",
      "Epoch [171/250], Loss: 231851720704.0000\n",
      "Epoch [172/250], Loss: 231851556864.0000\n",
      "Epoch [173/250], Loss: 231851393024.0000\n",
      "Epoch [174/250], Loss: 231851229184.0000\n",
      "Epoch [175/250], Loss: 231851081728.0000\n",
      "Epoch [176/250], Loss: 231850934272.0000\n",
      "Epoch [177/250], Loss: 231850770432.0000\n",
      "Epoch [178/250], Loss: 231850606592.0000\n",
      "Epoch [179/250], Loss: 231850459136.0000\n",
      "Epoch [180/250], Loss: 231850311680.0000\n",
      "Epoch [181/250], Loss: 231850147840.0000\n",
      "Epoch [182/250], Loss: 231850016768.0000\n",
      "Epoch [183/250], Loss: 231849836544.0000\n",
      "Epoch [184/250], Loss: 231849672704.0000\n",
      "Epoch [185/250], Loss: 231849541632.0000\n",
      "Epoch [186/250], Loss: 231849345024.0000\n",
      "Epoch [187/250], Loss: 231849213952.0000\n",
      "Epoch [188/250], Loss: 231849066496.0000\n",
      "Epoch [189/250], Loss: 231848902656.0000\n",
      "Epoch [190/250], Loss: 231848738816.0000\n",
      "Epoch [191/250], Loss: 231848624128.0000\n",
      "Epoch [192/250], Loss: 231848443904.0000\n",
      "Epoch [193/250], Loss: 231848280064.0000\n",
      "Epoch [194/250], Loss: 231848116224.0000\n",
      "Epoch [195/250], Loss: 231847968768.0000\n",
      "Epoch [196/250], Loss: 231847804928.0000\n",
      "Epoch [197/250], Loss: 231847657472.0000\n",
      "Epoch [198/250], Loss: 231847493632.0000\n",
      "Epoch [199/250], Loss: 231847329792.0000\n",
      "Epoch [200/250], Loss: 231847182336.0000\n",
      "Epoch [201/250], Loss: 231847051264.0000\n",
      "Epoch [202/250], Loss: 231846854656.0000\n",
      "Epoch [203/250], Loss: 231846707200.0000\n",
      "Epoch [204/250], Loss: 231846559744.0000\n",
      "Epoch [205/250], Loss: 231846412288.0000\n",
      "Epoch [206/250], Loss: 231846281216.0000\n",
      "Epoch [207/250], Loss: 231846100992.0000\n",
      "Epoch [208/250], Loss: 231845937152.0000\n",
      "Epoch [209/250], Loss: 231845756928.0000\n",
      "Epoch [210/250], Loss: 231845642240.0000\n",
      "Epoch [211/250], Loss: 231845462016.0000\n",
      "Epoch [212/250], Loss: 231845330944.0000\n",
      "Epoch [213/250], Loss: 231845167104.0000\n",
      "Epoch [214/250], Loss: 231845019648.0000\n",
      "Epoch [215/250], Loss: 231844839424.0000\n",
      "Epoch [216/250], Loss: 231844708352.0000\n",
      "Epoch [217/250], Loss: 231844511744.0000\n",
      "Epoch [218/250], Loss: 231844364288.0000\n",
      "Epoch [219/250], Loss: 231844233216.0000\n",
      "Epoch [220/250], Loss: 231844052992.0000\n",
      "Epoch [221/250], Loss: 231843905536.0000\n",
      "Epoch [222/250], Loss: 231843774464.0000\n",
      "Epoch [223/250], Loss: 231843610624.0000\n",
      "Epoch [224/250], Loss: 231843446784.0000\n",
      "Epoch [225/250], Loss: 231843299328.0000\n",
      "Epoch [226/250], Loss: 231843102720.0000\n",
      "Epoch [227/250], Loss: 231842955264.0000\n",
      "Epoch [228/250], Loss: 231842840576.0000\n",
      "Epoch [229/250], Loss: 231842676736.0000\n",
      "Epoch [230/250], Loss: 231842480128.0000\n",
      "Epoch [231/250], Loss: 231842332672.0000\n",
      "Epoch [232/250], Loss: 231842201600.0000\n",
      "Epoch [233/250], Loss: 231842054144.0000\n",
      "Epoch [234/250], Loss: 231841906688.0000\n",
      "Epoch [235/250], Loss: 231841726464.0000\n",
      "Epoch [236/250], Loss: 231841579008.0000\n",
      "Epoch [237/250], Loss: 231841431552.0000\n",
      "Epoch [238/250], Loss: 231841251328.0000\n",
      "Epoch [239/250], Loss: 231841103872.0000\n",
      "Epoch [240/250], Loss: 231840956416.0000\n",
      "Epoch [241/250], Loss: 231840792576.0000\n",
      "Epoch [242/250], Loss: 231840628736.0000\n",
      "Epoch [243/250], Loss: 231840481280.0000\n",
      "Epoch [244/250], Loss: 231840333824.0000\n",
      "Epoch [245/250], Loss: 231840169984.0000\n",
      "Epoch [246/250], Loss: 231840006144.0000\n",
      "Epoch [247/250], Loss: 231839858688.0000\n",
      "Epoch [248/250], Loss: 231839711232.0000\n",
      "Epoch [249/250], Loss: 231839547392.0000\n",
      "Epoch [250/250], Loss: 231839399936.0000\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:56.981789Z",
     "start_time": "2024-12-05T11:51:56.977177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Testing phase (metrics evaluation)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).squeeze()  # Predicted values\n",
    "    y_test_numpy = y_test.numpy()                # Actual test values (convert to numpy for metrics)\n",
    "    y_test_pred_numpy = y_test_pred.numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test_numpy, y_test_pred_numpy)\n",
    "    mse = mean_squared_error(y_test_numpy, y_test_pred_numpy)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_numpy, y_test_pred_numpy)\n",
    "\n",
    "    print(f\"Test Metrics:\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n"
   ],
   "id": "27b6dfccfc55bed8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "  MAE:  461070.4375\n",
      "  MSE:  240967368704.0000\n",
      "  RMSE: 490884.2812\n",
      "  R²:   -7.4853\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T11:51:57.005816Z",
     "start_time": "2024-12-05T11:51:57.004496Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fdf77d0cad1dd231",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
